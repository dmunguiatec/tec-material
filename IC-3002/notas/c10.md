---
title: "Capítulo 10. Algoritmos probabilísticos"
author: "Diego Munguía Molina ^[Esta obra está bajo una Licencia Creative Commons Atribución 4.0 Internacional.]"
date: "Julio, 2020"
institute: "Ingeniería en Computación, TEC"
geometry: margin=1in
header-includes:
    - \usepackage{setspace}
    - \usepackage{comment}
    - \providecommand{\subtitle}[1]{\usepackage{titling} \posttitle{\par\large#1\end{center}}}
    - \usepackage[spanish]{babel}
    - \usepackage[linesnumbered,ruled,vlined,spanish,onelanguage]{algorithm2e}
    - \usepackage{amssymb}
    - \SetKwInput{KwInput}{Entradas}
    - \SetKwInput{KwOutput}{Salidas}
    - \newcommand{\twodots}{\mathrel{{.}\,{.}}\nobreak}
    - \newcommand{\assign}{\leftarrow}
    - \DeclareMathOperator{\ordenar}{ordenar}
    - \DeclareMathOperator{\bits}{bits}
    - \DeclareMathOperator{\azar}{azar}
output:
  pdf_document:
    latex_engine: xelatex
---

¿Cuál es el alcance de las relaciones causa/efecto? ¿Es posible explicar cualquier evento identificando sus causas? ¿Si conocemos de antemano las causas podemos determinar cuál será el efecto? Estas son preguntas filosóficas relacionadas con el problema del **determinismo**. A grandes rasgos (y con poca precisión) podemos caracterizar que el mundo es determinista si el estado específico de las cosas en un instante $t$ determina, como una ley natural, cómo serán las cosas después de $t$.

En otras palabras, en un mundo determinista el presente constituye las causas de cómo serán los eventos en el futuro; y, al mismo tiempo, el presente es efecto de las causas del pasado. De esta forma, el futuro ya estaría determinado por el presente, y sería imposible cambiarlo.

Cuando hablamos del estado del mundo en esta definición nos referimos a la consideración de todas las variables posibles en dicho instante, por ejemplo el que haya llovido hoy podría haberse debido al efecto combinado de una serie de eventos anteriores, por ejemplo: los movimientos de un cardumen en el Mar Caribe, la caída de una roca en los Andes, el florecimiento de un árbol en Galápagos, una tormenta de arena en el Sahara, o una explosión en el Sol, entre otra inmensidad de variables posibles.

Por otro lado, cuando hablamos de leyes naturales nos referimos a cómo se relacionan los diferentes eventos entre sí en nuestro universo, por ejemplo: una canica estática en el suelo se moverá si es golpeada por otra canica, o el agua hervirá cuando se calienta a 100 grados celsius en un lugar al nivel del mar.

Si el mundo es determinista, entonces la idea del libre albedrío en los seres humanos pierde sentido. En un mundo como tal, todas las acciones y decisiones que tome una persona en un momento determinado estarán en función del estado del mundo en momentos anteriores y no en función de su propia voluntad.

Un mundo determinista también tiene implicaciones sobre la fundamentación y finalidad de la práctica científica. Específicamente, la búsqueda de teorías con capacidad predictiva requiere de un cierto nivel de determinismo en el mundo.

No conocemos una respuesta definitiva al problema del determinismo, pues incluso a nivel de la mecánica cuántica se esgrimen argumentos a favor y en contra.

El concepto opuesto al determinismo es la **aleatoriedad**. Un proceso aleatorio —también llamado estocástico o no-determinístico— carece de predictabilidad. Es decir, no presenta un patrón de eventos que permita determinar a partir de un estado inicial $e_t$ cuál será un estado futuro $e_{t+k}$.

Finalmente cabe señalar que el problema del determinismo es propio del pensamiento occidental, pues requiere de una cosmovisión particular en la que el tiempo sea lineal; es decir si $t$ es el instante presente, $t-1$ está en el pasado y $t+1$ en el futuro.

Este problema no tiene cabida, por ejemplo, desde la filosofía andina donde la concepción del tiempo es más bien cíclica y las relaciones causales son esenciales pero no necesarias. Intuitivamente podemos explicar esta idea de esencialidad utilizando una analogía con el juego de ajedrez; este presenta una serie de relaciones entre las piezas y el tablero —las posibles movidas— normadas por las reglas del juego (esencialidad), sin embargo no hay una restricción física que evite realizar una movida ilegal —las movidas concretas no obedecen a una necesidad—. En otras palabras, desde la filosofía andina no se considera la ley natural como si lo hace la filosofía occidental.

En este capítulo estudiaremos primero cómo se manifiesta el problema del determinismo en las ciencias de la computación y a partir de esto, cómo podemos aplicar la aleatoriedad (o pseudoaleatoriedad) a la resolución de problemas computacionales.

## Generadores de números pseudoaleatorios ##

Cuando reducimos el mundo discursivo en la caracterización de determinismo a una computadora —sea esta una máquina de Turing o una máquina con arquitectura Von Neumann— podemos obtener resultados más específicos.

El funcionamiento de la computadora presupone un comportamiento lineal del tiempo. El proceso de ejecución de la máquina corresponde a una secuencia lineal de estados, a partir del estado actual $e_t$ la aplicación de una operación lleva a la máquina a un estado $e_{t+1}$. Aún más, tanto los instantes como los estados son discretos y bien determinados; la máquina cuenta con un reloj que marca el ritmo con el que se mueve la máquina de un estado a otro.

El estado de este mundo reducido es bien delimitado y manejable, corresponde al estado de los registros, las diferentes unidades de memoria, y los dispositivos de entrada y salida. Adicionalmente, cuenta con un conjunto bien definido de operaciones, cada una de las cuales permite transicionar de un estado actual al siguiente. Estas operaciones se organizan en programas que son ejecutados por la máquina como procesos; los programas son almacenados como parte del estado de la máquina.

De esta forma dado un estado actual de la máquina, podemos saber cuál es la siguiente operación a ejecutar y por tanto cuál será el próximo estado. La computadora constituye entonces un mundo determinista. Este determinismo puede crecer en complejidad cuando se involucra la entrada del usuario —aunque estas tienden a estar acotadas— o cuando se considera la posibilidad de ejecutar distintos procesos concurrentemente[^1], sin embargo esta creciente complejidad no implica necesariamente la presencia de aleatoriedad.

[^1]: Como estudiaremos en el próximo capítulo, la ejecución concurrente de procesos es una técnica que permite maximizar el uso del procesador al tiempo que da la ilusión al usuario de que dos o más programas se ejecutan al mismo tiempo.

La simulación de fenómenos naturales, eventos estadísticos y los métodos criptográficos, entre otras posibles aplicaciones computacionales introducen un requerimiento de aleatoriedad en el comportamiento de los algoritmos. De antemano, esto presupone que el mundo presenta algún nivel de aleatoriedad, o en otras palabras que no es totalmente determinístico.

Estrictamente no existe tal cosa como un número aleatorio, el carácter aleatorio viene dado por la necesidad de seleccionar azarosamente una serie de números, es decir sin que medie alguna relación específica entre ellos. De esta forma la aleatoriedad es una propiedad de la secuencia y no de un número específico. Sin embargo, en la literatura se habla comúnmente de números aleatorios para referirse a estas secuencias aleatorias.

Una manera de introducir aleatoriedad en un algoritmo es través de la entrada manual de valores aleatoriamente. Esta es una solución poco práctica pues interfiere con la velocidad de cálculo de la computadora y se convierte en una tarea difícil conforme aumenta el número de entradas requeridas.

Históricamente se han creado manualmente tablas aleatorias de valores que pueden ser alimentadas a los algoritmos como entradas. Una tabla como estas se puede construir lanzando dados, utilizando naipes, o con algún otro medio semejante. Por ejemplo, podríamos hacer una serie de lanzamientos de moneda, donde una cara represente un 1 y la otra cara un 0; cada lanzamiento nos permite registrar entonces un bit aleatorio. El uso de estas tablas impone un requerimiento de uso de memoria, que era especialmente problemático para las primeras computadoras digitales. Es necesario considerar también que construir estas tablas requiere de un enorme esfuerzo de trabajo manual.

Es necesario también considerar que la introducción de aleatoriedad representa un problema para la verificación de los algoritmos. Los resultados de una función aleatoria no son reproducibles y por tanto es mucho más complicado identificar errores en el algoritmo o su implementación.

Una tercera opción, que es más práctica pero menos rigurosa, es el uso de generadores de números pseudoaleatorios. Estos son métodos aritméticos para calcular una secuencia de números. Esta secuencia no será aleatoria pues el método que la genera es determinístico por definición, más bien será aparentemente aleatoria —de ahí el término **pseudoaleatorio**—.

Los generadores pseudoaleatorios de números parten de una semilla inicial, un número dado como entrada, y a partir de este calculan el próximo número de la secuencia, este nuevo número será la entrada para generar el siguiente y así sucesivamente. Formalmente podemos definirlo de la siguiente manera.

$$
\begin{aligned}
s_0 &= semilla \\
s_{i+1} &= f(s_i), i = 0, 1, \dots \\
\end{aligned}
$$

La expresión seleccionada para nuestro generador $f$ tiene como requisito que posea propiedades estadísticas que se aproximen a la de una secuencia realmente aleatoria. Determinar estas propiedades se sale del alcance de este capítulo, por tanto nada más estudiaremos algunos métodos de ejemplo que nos permitan identificar otras características importantes que utilizaremos en nuestros algoritmos probabilísticos.

### Método del cuadrado del medio ###

Este fue el primer generador pseudoaleatorio propuesto al inicio de la computación contemporánea. El método consiste de los siguientes pasos:

1. Se parte de un número de $n$ dígitos. Este será el primer número $s_0$ de la secuencia.
2. Se eleva este número al cuadrado para obtener un número de $2n$ dígitos. Si el resultado tiene menos de $2n$ dígitos se completan con ceros al frente.
3. Del número resultante se toman los $n$ dígitos del medio. Este será el siguiente número de la secuencia.
4. Se repite el paso 1 con el número recién calculado.

Por ejemplo.

$$
\begin{aligned}
s_0 &= 2156 \\
s_0^2 &= 04\textbf{6483}36 \\
s_1 &= 6483 \\
s_1^2 &= 42\textbf{0292}89 \\
s_2 &= 0292 \\
\vdots
\end{aligned}
$$

Este método no es particularmente robusto. Para entender por qué, consideremos el siguiente ejemplo.

$$
\begin{aligned}
s_0 &= 0540 \\
s_0^2 &= 00\textbf{2916}00 \\
s_1 &= 2916 \\
s_1^2 &= 08\textbf{5030}56 \\
s_2 &= 5030 \\
s_2^2 &= 25\textbf{3009}00 \\
s_3 &= 3009 \\
s_3^2 &= 09\textbf{0540}81 \\
s_4 &= 0540
\end{aligned}
$$

A partir de $s_3$ la secuencia se seguirá repitiendo indefinidamente, sabemos que $s_5$ será $2916$, $s_6$ será $5030$ y así sucesivamente. Decimos entonces que la secuencia con la semilla $0540$ tiene un período $= 4$. La secuencia con la semilla $0000$ tiene período $0$. En general, en el momento en que se repita un número en la secuencia —no necesariamente la semilla— el método caerá en un ciclo.

El **período** se refiere entonces a la longitud de la secuencia, o cuántos números podrá generar el método con una serie de parámetros específicos hasta que se repita alguno.

En el caso de este método, la selección de una semilla equivocada puede llevarnos a producir una secuencia de período corto introduciendo patrones indeseados en nuestro algoritmo.

### Método congruencial lineal ###

Este método es muy utilizado, por ejemplo en las bibliotecas estándar de Java y C. Se calcula de la siguiente manera:

Sea

* $m, 0 < m$, el módulo
* $a, 0 \leq a < m$, el multiplicador
* $c, 0 \leq c < m$, el incrementador
* $s_0, 0 \leq s_0 < m$, la semilla

entonces

$$
s_{i+1} = (a \cdot s_i + c) \mod m, n \geq 0
$$

Esta función puede generar períodos de hasta $m$ elementos. En el caso de la función `rand()` de la biblioteca estándar de C se utiliza la siguiente versión.

$$
\begin{aligned}
s_0 &= 12345 \\
s_{i+1} &= 1103515245 \cdot s_i + 12345 \mod 2^{31}, i = 0, 1, \dots
\end{aligned}
$$

Este método también tiene la propiedad de generar números con una **distribución uniforme**. Esto quiere decir que cada número es equiprobable, o que tiene la misma probabilidad que cualquier otro número de aparecer en la secuencia.

Para determinar las propiedades estadísticas de un generador específico, y qué tanto se acercan a una serie realmente aleatoria, se aplica un serie de pruebas estadísticas por ejemplo chi-cuadrado, o Kolmogorov-Smirnov.

### Ejercicios ###

1. Investigue el concepto de generador en python (y el estatuto `yield`) e implemente una función que genere una secuencia pseudoaleatoria utilizando el método congruencial lineal con los mismos parámetros que la función `rand()` de C.

2. ¿Cómo podríamos utilizar esta misma función para generar números aleatorios en el rango $[0, 1]$?

## Algoritmos probabilísticos ##

En esta sección estudiaremos algunos algoritmos de búsqueda que dependen de generadores pseudoaleatorios para encontrar soluciones. El uso de aleatoriedad introduce el aspecto probabilístico en estos algoritmos, y este está directamente relacionado ya sea con que se encuentre una solución o no, y si hay alguna entonces cuál es su precisión, o cuánto tiempo se requiere para encontrarla.

Estos algoritmos pueden ser de dos tipos:

* Monte Carlo: garantizan un tiempo de ejecución eficiente (aspecto determinístico), pero no garantizan que se encuentre la solución correcta (aspecto no-determinístico).

* Las Vegas: garantizan que se encontrará la solución correcta (aspecto determinístico), pero no garantizan que el tiempo de ejecución sea eficiente (aspecto no-determinístico).

Con base en esta caracterización podemos observar que la clasificación de nuestro algoritmo va a depender de cómo se utilice la pseudoaleatoriedad en el diseño del mismo. Estudiemos algunos ejemplos.

### Monte Carlo ###

Consideremos el problema de determinar si un número $n$ es primo. La solución ingenua es probar si $n \mod i \neq 0$ para todos los números $i$ en el rango $[2 \twodots n[$, esta solución tiene complejidad $\mathcal{O}(n)$ y es poco práctica para $n$s muy grandes.

Si utilizamos el teorema pequeño de Fermat y un algoritmo Monte Carlo podemos obtener una solución más eficiente, aunque posiblemente equivocada (con una baja probabilidad). Consideremos entonces el siguiente problema computacional.

(@) **Problema**. Test de primalidad.  
  **Entradas**. Un número natural $n$ y un número natural $k$ tal que $1 \leq k < n$.  
  **Salida**. $1$ cuando es probable que $n$ sea primo de acuerdo con la prueba del teorema pequeño de Fermat, $0$ en cualquier otro caso.  

Utilizaremos los siguientes teoremas clásicos de teoría de números (que no demostraremos por salir del alcance de este capítulo).

(1) **Teorema**. Si un entero $p$ es primo, entonces para cada entero $a$ tal que $1 \leq a < p$ se cumple

$$
a^{p-1} \mod p = 1
$$

(2) **Teorema**. Si un entero $p$ no es primo, entonces no más de la mitad de los enteros $a \in [1 \twodots p[$ satisfacen la ecuación del teorema 2.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Un número natural $n$ y un número natural $k$ tal que $1 \leq k < n$.}
    \KwOutput{$1$ cuando es probable que $n$ sea primo de acuerdo con la prueba del teorema pequeño de Fermat, $0$ en cualquier otro caso.}
  
    \BlankLine
    \caption{Test de primalidad.}
    \SetAlgoVlined
    
    \For{$i \in [1 \twodots k]$} {
        $a \assign \azar(2, n-1)$ \;
        \If{$a^{n-1} \mod n \neq 1$} {
            \Return{$0$} \;
        }
    }

    \Return{$1$} \;
\end{algorithm}

Este algoritmo prueba $k$ números $a$ tomados al azar del rango $[2, n[$, si alguno de estos falla entonces determinamos que $p$ no es primo. Si probamos exitosamente los $k$ números $a$ entonces suponemos que $p$ es primo, ¿pero con cuánta confiabilidad podemos hacer este supuesto?

Si ejecutamos el algoritmo con $k = 1$ y un $n$ no primo, según el teorema 2, podemos esperar una probabilidad máxima de error de 50%, puesto que podríamos haber seleccionado un $a$ de la mitad esperada que pase la prueba.

Para analizar el caso con $k = 2$, podemos definir el evento $A$ como la probabilidad de seleccionar el primer número $a$ de la mitad que pasará la prueba y el evento $B$ como la probabilidad de seleccionar el segundo número $a$ de la mitad que pasará la prueba. Sabemos que el evento $B$ es independiente del evento $A$ puesto que la selección del primer número $a$ no afecta las probabilidades de la selección del segundo número $a$ ya que ambas se toman al azar de una secuencia de distribución uniforme.

Dado que $A$ y $B$ son independientes, entonces $P(A \land B) = P(A) \cdot P(B)$. Por tanto tenemos que la probabilidad de haber seleccionado ambos números de la mitad que pasa la prueba es $P(err) = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}$, es decir podemos esperar una probabilidad máxima de error del 25%.

Siguiendo la misma lógica, con $k=3$ tendremos entonces $P(err) = \frac{1}{2} \cdot \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{8}$. En general obtenemos que $P(err) = \frac{1}{2^k}$, es decir que la probabilidad de error esperado decrece exponencialmente conforme probamos más números $a$. Con $k=10$ la probabilidad de error es de aproximadamente 0.1%, no importa qué tan grande sea nuestro número $n$.

### Las Vegas ###

Reconsideremos ahora el problema de encontrar un número en una secuencia desordenada de números.

(@) **Problema**. Buscar un elemento en una secuencia.  
  **Entradas**. Una secuencia de números $A = [a_1, a_2, \dots, a_n]$ y un número $e$.  
  **Salida**. Un índice $i \in [0 \twodots n[$ tal que $A[i] = e$, o $-1$ cuando $e \notin A$.  

Dado que la secuencia está desordenada, la solución ingenua a este problema es recorrer la secuencia de principio a fin buscando el elemento $e$. Alternativamente podemos introducir aleatoriedad en un diseño Las Vegas para saltar hacia adelante y atrás en la búsqueda, con la expectativa de que si el elemento buscado esté hacia el final de la secuencia podamos encontrarlo antes de recorrer todos los elementos anteriores.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Una secuencia de números $A = [a_1, a_2, \dots, a_n]$ y un número $e$.}
    \KwOutput{Un índice $pos \in [0 \twodots n[$ tal que $A[pos] = e$, o $-1$ cuando $e \notin A$.}
  
    \BlankLine
    \caption{Búsqueda Las Vegas.}
    \SetAlgoVlined
    
    \For{$i \in [0 \twodots n[$} {
        $pos \assign \azar(0, n-1)$ \;
        \If{$A[pos] = e$} {
            \Return{$pos$} \;
        }
    }

    \Return{$-1$} \;
\end{algorithm}

Este algoritmo recorre la secuencia aleatoriamente determinando cuál es el próximo índice a investigar en la línea 2. Si el elemento $e$ no está en la secuencia, se investigarán todos los índices antes de determinar el fallo; si el elemento si está en la secuencia el algoritmo repetirá entre 1 y $n$ veces. Este comportamiento garantiza que siempre obtendrá la solución correcta.

Por otro lado, el aspecto del tiempo de ejecución no está determinado, es posible que el elemento se encuentre en la primera posición obtenida al azar o en la última o en cualquiera en el medio de ambos extremos. En el peor de los casos se investigarán todas las posiciones de la secuencia.

Para que este algoritmo funcione correctamente debemos asegurarnos que los índices obtenidos al azar en la línea 2 no se repitan.

### Ejercicios ###

1. Proponga un algoritmo Monte Carlo para la búsqueda aleatoria. Calcule la probabilidad de error para su algoritmo.

## Optimización estocástica ##

A continuación estudiaremos una serie de algoritmos probabilísticos para resolver problemas de búsqueda combinatoria. Recordamos que estos problemas requieren de la búsqueda de soluciones óptimas modeladas como combinaciones de múltiples variables. Por ejemplo en el problema de corte de varilla se manejan las variables de cantidad de fragmentos, tamaño de cada fragmento y valor asociado con cada fragmento, mientras que en el problema de selección de actividades se trabaja con la cantidad de actividades, y las horas de inicio y finalización de cada actividad. Esta característica combinatoria implica que los problemas usualmente cuentan con una vastedad de posibles soluciones, provocando que sea impráctico verificarlas una por una.

Los algoritmos de optimización realizan una búsqueda dirigida en el espacio de soluciones partiendo de un punto al azar. Cada solución encontrada es evaluada cuantitativamente, esta evaluación incluye la variable que se busca optimizar —maximizándola o minimizándola dependiendo del contexto del problema—. El mecanismo de búsqueda aplica pequeños cambios a las soluciones encontradas para producir nuevas soluciones con el objetivo de mejorar la evaluación con cada cambio.

Estos algoritmos pueden introducir aleatoriedad tanto en los valores de la variables que componen las soluciones, como en la evaluación y el mecanismo de dirección de la búsqueda. Es por esta aleatoriedad característica que se clasifican como estocásticos.

## El problema del vendedor viajero ##

El problema que utilizaremos para ilustar los algoritmos de optimización es el del vendedor viajero. Este problema parte de una colección de ciudades todas interconectadas entre si. Un vendedor viajero necesita definir la ruta más corta que le permita visitar a cada una de estas ciudades sólo una vez, empezando y finalizando la gira en la misma ciudad.

Desde la teoría de grafos podemos replantear el problema de la siguiente manera.

(@) **Problema**. Vendedor viajero.  
  **Entradas**. Un grafo completo $G$.  
  **Salida**. El camino cíclico de peso mínimo, sin elementos repetidos, que pase por cada uno de los vértices de $G$.

La figura $\ref{fig:tsp}$ presenta un ejemplo concreto con las ciudades del Valle Central de Costa Rica. El grafo representa las distancias en km que hay entre Alajuela, Heredia, San José y Cartago.

![Vendedor viajero en el Valle Central\label{fig:tsp}](plots/VendedorViajero.png)

Las soluciones al problema se pueden representar como secuencias de símbolos, donde cada símbolo representa una ciudad. Por ejemplo $[A, C, SJ, H]$ representa una solución en la que se parte de Alajuela hacia Cartago, luego se visita San José, y finalmente Heredia, retornando de ahí hacia Alajuela.

El tamaño de la secuencia corresponderá al número de ciudades por visitar, y la secuencia no admite repetidos. Con estas restricciones nos aseguramos que se visiten todas las ciudades y que cada ciudad se visite una única vez. Finalmente, el ciclo lo completamos tomando en cuenta que de la última ciudad en la secuencia hay un traslado final a la primera ciudad en la secuencia.

Las soluciones se evaluarán con una función de costo $f_{costo}$ definida como la sumatoria de las distancias entre los traslados especificados por la secuencia de los símbolos en la secuencia, obteniendo de esta forma la distancia total de la ruta. Tomemos como referencia las distancias en la figura $\ref{fig:tsp}$. Tenemos entonces que:

$$
f_{costo}([A, C, SJ, H]) = 46.3 + 28.1 + 10.8 + 12.3 = 97.5
$$

$$
f_{costo}([A, C, H, SJ]) = 46.3 + 38.4 + 10.8 + 18.8 = 114.3
$$

El objetivo entonces es minimizar la función de costo para minimizar la distancia recorrida, en busca de la ruta más corta.

Cabe notar que por simplicidad nuestro ejemplo es bastante trivial pues sólo trabaja con cuatro ciudades y por tanto podría ser solucionado rápidamente con una búsqueda por fuerza bruta. Sin embargo, cabe notar que el número de soluciones posibles para el problema en general corresponde al número de permutaciones de la secuencia $n!$ donde $n$ es el tamaño de la secuencia. La búsqueda por fuerza bruta tiene entonces una complejidad temporal de $\mathcal{O}(n!)$, haciéndola intratable para un número mayor de ciudades[^2].

[^2]: Pensemos por ejemplo visitar todas las ciudades de América en avión.

A continuación estudiaremos cuatro algoritmos de optimización estocástica que nos permiten acercarnos a solucionar este problema y otros que se puedan representar de manera similar como secuencias de variables: búsqueda aleatoria, *hill climbing*, *simulated annealing*, y algoritmos genéticos.

## Búsqueda aleatoria ##

Este algoritmo simplemente genera una serie de soluciones al azar, buscando optimizar su evaluación en cada iteración. En este y todos los demás casos presentaremos algoritmos que minimizan su función de costo.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Un objeto $dominio$ que puede generar posibles soluciones, y un número $n$ de repeticiones a realizar.}
    \KwOutput{La solución con menor costo encontrada.}
  
    \BlankLine
    \caption{Búsqueda aleatoria para resolver problema de búsqueda combinatoria.}
    \SetAlgoVlined

    $costo_{min} \assign \infty$ \;
    $sol_{min} \assign \varnothing$ \;
    \For{$i \in [1 \twodots n]:$} {
      $sol \assign dominio.generar()$ genera solución al azar \;
      $costo \assign dominio.f_{costo}(sol)$ \;
      \If{$costo < costo_{min}$} {
        $costo_{min} \assign costo$ \;
        $sol_{min} \assign sol$ \;
      }
    }

    \Return{$sol_{min}$} \;
\end{algorithm}

El algoritmo recibe un objeto $dominio$, la responsabilidad de este objeto es manejar los detalles particulares de la representación del problema —en nuestro caso la secuencia de ciudades—. De esta forma, el objeto de dominio "sabe" cómo generar soluciones al azar y también cómo evaluar soluciones.

### Ejercicios ###

1. ¿Cuál es la probabilidad de que encuentre la mejor solución para nuestro problema del vendedor viajero?

2. ¿Qué utilidad puede tener un algoritmo de búsqueda aleatoria?

## Hill climbing ##

Este algoritmo identifica el proceso de optimización con la metáfora de escalar una colina, llegar al tope de la colina equivale a encontrar la solución óptima. El buscador es un agente que escala una colina, y que después de cada paso que da se detiene a mirar a su alredor, buscando el camino que lo siga llevando hacia la cima.

![Hill Climbing\label{fig:hill}](plots/HillClimbing.png)

La figura $\ref{fig:hill}$ ilustra esta metáfora. Dada una solución aleatoria, representada por el punto negro, se generan soluciones próximas o vecinas —soluciones que varíen en algunos pequeños detalles con respecto a la actual—. El costo de cada solución vecina es evaluado y comparado con la solución actual, el objetivo es encontrar un vecino que mejore en costo y que por tanto me acerque más a la cima de la colina. El algoritmo se detiene cuando ninguno de los vecinos produce un costo mejor que el de la solución actual, interpretando que si ya no puedo seguir escalando en ninguna dirección es porque ya estoy en el punto más alto de la colina.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Un objeto $dominio$ que puede generar posibles soluciones.}
    \KwOutput{La solución con menor costo encontrada.}
  
    \BlankLine
    \caption{Búsqueda $\textit{hill climbing}$ para resolver problema de búsqueda combinatoria.}
    \SetAlgoVlined
    \SetKwBlock{Loop}{repetir}{}{}


    $sol \assign dominio.generar()$ genera solución al azar  \;
    $sol_{min} \assign sol$ \;
    $costo_{min} \assign dominio.f_{costo}(sol)$ \;
    \Loop {
      $vecinos \assign dominio.vecinos(sol)$ \;
      \For{$v \in vecinos:$} {
        $costo_{v} \assign dominio.f_{costo}(v)$ \;
        \If{$costo_{v} < costo_{min}$} {
          $costo_{min} \assign costo_{v}$ \;
          $sol_{min} \assign v$ \;
        }
      }
      \If{$sol_{min} = sol$} {
        \Return{$sol$} \;
      }
      \Else {
        $sol \assign sol_{min}$ \;
      }
    }{}
\end{algorithm}

Notemos que el algoritmo se desarrolla dentro de un ciclo infinito que sólo se puede interrumpir cuando se llega a un tope —cuando ninguno de los vecinos mejora a la solución actual—. A diferencia de la búsqueda al azar —controlada por el parámetro $n$—, con *hill climbing* no tenemos control sobre el tiempo que va a tardar el algoritmo ejecutándose, pero si tenemos garantía de que el algoritmo va a llegar a un tope[^3].

[^3]: Podríamos afirmar entonces que *hill climbing* se puede categorizar como un algoritmo Las Vegas, mientras que la búsqueda aleatoria se categoriza como un algoritmo Monte Carlo.

Este es un algoritmo voraz que funciona bien cuando el espacio de búsqueda se comporta como una colina en la que siempre hay claridad sobre cuál camino sigue escalando y cuál camino me lleva de vuelta hacia abajo.

Sin embargo, son comúnes las situaciones en las que el espacio de búsqueda contiene cimas locales —también llamadas máximos locales— tal y como lo ilustra la figura 3. En estas situaciones, el algoritmo por su voracidad se detendrá en la primer cima local que encuentre.

![Máximo local\label{fig:hill_local}](plots/HillClimbingMaxLocal.png)

Como observamos en la figura $\ref{fig:hill_local}$, todas las soluciones vecinas a la solución actual son caminos de descenso. El algoritmo es incapaz de ver más allá del diámetro de su vecindario y por tanto no cae en cuenta de la presencia de una colina aún más alta que la actual. Podríamos pensar en aumentar el radio del vecindario con la esperanza de proveer al algoritmo con una mejor visibilidad. Sin embargo, el máximo local y el máximo absoluto podrían estar colocados en extremos diametralmente opuestos del espacio de búsqueda; aumentar el radio del vecindario potencialmente podría transformar nuestro *hill climbing* en una búsqueda por fuerza bruta.  

### Ejercicios ###

1. ¿Qué estrategias podemos proponer para generar los vecinos para nuestro problema específico del vendedor viajero?

2. ¿Cómo podemos mitigar el problema de los máximos locales, manteniendo el comportamiento de *hill climbing*?

## *Simulated annealing* ##

*Annealing* por su nombre en inglés es un proceso metalúrgico en el que se calienta un metal a altas temperaturas y luego se le deja enfriar lentamente. Este proceso tiene como objetivo alterar algunas propiedades del metal como su dureza o maleabilidad. El cambio se logra gracias a que el proceso de calentamiento aumenta la energía en los átomos y luego el enfriamiento produce nuevas configuraciones atómicas de baja energía.

El algoritmo de *simulated annealing* es metáfora de este proceso. El mecanismo es similar a los dos algoritmos anteriores, se generan soluciones al azar y luego aplicando pequeños cambios se producen nuevas soluciones. Cada solución es evaluada, y se busca optimizar su costo.

La diferencia con *hill climbing* radica en reducir su voracidad aceptando algunas soluciones que nos lleven en dirección de descenso. Estas soluciones serán aceptadas con base en una probabiblidad que se calcula en cada iteración. Con este mecanismo tratamos de reducir la probabilidad de quedar atascados en una cima local.

La simulación del proceso de enfriamiento determinará cuántas repeticiones realizará el algoritmo.  

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Un objeto $dominio$ que puede generar posibles soluciones, un número entero $temp$ que representa la temperatura inicial y un número $tasa_{enfr} \in [0, 1]$.}
    \KwOutput{La solución con menor costo encontrada.}
  
    \BlankLine
    \caption{Búsqueda $\textit{simulated annealing}$ para resolver problema de búsqueda combinatoria.}
    \SetAlgoVlined

    $sol \assign dominio.generar()$ genera una solución al azar \;
    $costo \assign dominio.f_{costo}(sol)$ \;
    \While{$temp > 0.01$} {
      $sol^\prime \assign dominio.vecino(sol)$ Genera un vecino al azar \;
      $costo^\prime \assign dominio.f_{costo}(sol^\prime)$ \;
      $p \assign \mathrm{e}^{\frac{-|costo^\prime-costo|}{temp}}$ \;
      $p_{azar} \assign \azar(0, 1)$  número entre 0 y 1 en distribución uniforme \;
      \If{$costo^\prime < costo \lor  p_{azar} \leq p$} {
        $sol \assign sol^\prime$ \;
        $costo \assign costo^\prime$ \;
      }
      $temp \assign temp \times tasa_{enfr}$ \;
    }
    \Return{$sol$} \;
\end{algorithm}

### Ejercicios ###

1. Explique el papel que juega la variable $p$ en el comportamiento del algoritmo. Tome en cuenta que $\mathrm{e}^0 = 1$ y $\lim_{x \to -\infty} \mathrm{e}^x = 0$. ¿Qué papel juega la expresión $-|costo'-costo|$ en el cálculo de la probabilidad? ¿Qué papel juega $temp$ en el cálculo de la probabilidad?

2. ¿Porqué es importante que $p$ se obtenga al azar de una distribución uniforme?

3. ¿Porqué este algoritmo no me garantiza que siempre voy a evitar máximos locales?

## Algoritmos genéticos ##

Esta técnica se inspira en el proceso darwiniano de evolución por selección natural. Consiste en generar una serie de soluciones al azar, tomar una fracción de las mejor evaluadas, y a partir de ellas producir un nuevo conjunto de soluciones. Este proceso se repite varias veces buscando una convergencia hacia las mejores soluciones posibles.

El supuesto detrás de este mecanismo es que una combinación de soluciones buenas puede producir soluciones aún mejores.

El algoritmo sigue este esquema de pasos:

1. Generar una población de soluciones al azar.
2. Evaluar la población.
3. Seleccionar una élite las mejores soluciones de la población.
4. Producir una nueva generación de soluciones a partir de cruzamiento y mutación de la  élite.
5. Repetir a partir de paso (2) con nueva generación.

\begin{algorithm}[H]
    \DontPrintSemicolon
    \KwInput{Un objeto $dominio$ que puede generar posibles soluciones, un número entero $tam\_pobl$ que representa el tamaño de población, un número $prop\_elite \in [0, 1]$ que representa el porcentaje de la población que será considerado élite, un número $prob\_mut \in [0, 1]$ que representa la probabilidad de mutación y un número entero $n$ que indica el número de repeticiones.}
    \KwOutput{La solución con menor costo encontrada.}
  
    \BlankLine
    \caption{Búsqueda con algoritmo genético para resolver problema de búsqueda combinatoria.}
    \SetAlgoVlined

    $pobl \assign dominio.generar(tam\_pobl)$ \;
    \While{$n > 0$} {
      \For{$sol \in pobl$} {
        $sol.aptitud \assign dominio.f_{costo}(sol)$ \;
      }
      $\ordenar(pobl, llave = aptitud)$ \;
      $num\_padres \assign \lfloor (|pobl| \times prop\_elite) \rfloor$ \;
      $num\_hijos \assign (|pobl| - num\_padres)$ \;
      $sig\_gen \assign pobl[0:num\_padres]$ \;
      $descendencia \assign \varnothing$ \;
      \While{$num\_hijos > 0$} {
        $padre_A \assign sig\_gen[\azar()]$ escoge un índice al azar \;
        $padre_B \assign sig\_gen[\azar())]$ \;
        $hijo \assign dominio.cruzar(padre_A, padre_B)$ \;
        $p \assign \azar(0, 1)$ distribución uniforme \;
        \If{$p \leq prob\_mut$} {
          $hijo \assign dominio.mutar(hijo)$ \;
        }
        $descendencia \ll hijo$ \;
        $num\_hijos \assign num\_hijos - 1$ \;
      }
      $pobl \assign sig\_gen \ll descendencia$ \;
      $n \assign n - 1$ \;
    }
\end{algorithm}

### Ejercicios ###

1. ¿Cuáles deberían ser los valores para los parámetros del algoritmo:  $tam\_pobl$, $prop\_elite$, $prob\_mut$, $n$?

2. Proponga una función de cruzamiento y una función de mutación para el problema del vendedor viajero.

## Referencias ##

Estermann, J. (2006) Filosofía andina: Sabiduría indígena para un mundo nuevo. ISEAT.

Heineman G.T., Pollice G., Selkow G. (2009) Algorithms in a nutshell. O'Reilly.

Hoefer, C. (2016) "Causal Determinism", The Stanford Encyclopedia of Philosophy (Spring 2016 Edition), Edward N. Zalta (ed.). Disponible en https://plato.stanford.edu/archives/spr2016/entries/determinism-causal.

Knuth, D. (2014) The Art of Computer Programming, Volume 2, The: Seminumerical Algorithms. Addison-Wesley.

Paar, C., Pelzl J. (2010) Understanding Cryptography. Springer.

Sedgewick, R., Flajolet, P. (2013) An Introduction to the Analysis of Algorithms Addison-Wesley.

Segaran T. (2007) Programming collective intelligence. O'Reilly.

Vrajitoru, D., Knight, W. (2014). Practical Analysis of Algorithms. Springer.